{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. **Elastic Net Regression and its Differences from Other Regression Techniques:**\n",
        "   - Elastic Net Regression is a regularization technique that combines the penalties of both Lasso Regression (L1 penalty) and Ridge Regression (L2 penalty). It differs from other regression techniques by offering a compromise between the feature selection capabilities of Lasso Regression and the coefficient shrinkage properties of Ridge Regression.\n",
        "\n",
        "---\n",
        "\n",
        "Q2. **Choosing Optimal Values of Regularization Parameters for Elastic Net Regression:**\n",
        "   - The optimal values of the regularization parameters, alpha and l1_ratio, in Elastic Net Regression are typically chosen through techniques such as cross-validation. Grid search or randomized search can be used to search through a range of values for both parameters and select the combination that yields the best model performance.\n",
        "\n",
        "---\n",
        "\n",
        "Q3. **Advantages and Disadvantages of Elastic Net Regression:**\n",
        "   - Advantages:\n",
        "     - Combines the advantages of both Lasso and Ridge Regression, offering a balance between coefficient shrinkage and feature selection.\n",
        "     - Effective in handling multicollinearity and high-dimensional data.\n",
        "   - Disadvantages:\n",
        "     - Requires tuning of multiple hyperparameters, making it computationally expensive.\n",
        "     - Interpretability of the model may be challenging due to the combined penalty terms.\n",
        "\n",
        "---\n",
        "\n",
        "Q4. **Common Use Cases for Elastic Net Regression:**\n",
        "   - Elastic Net Regression is commonly used in scenarios where there are many correlated independent variables or when feature selection and regularization are desired. It finds applications in areas such as finance, economics, genetics, and bioinformatics.\n",
        "\n",
        "---\n",
        "\n",
        "Q5. **Interpreting Coefficients in Elastic Net Regression:**\n",
        "   - Similar to other regression techniques, the coefficients in Elastic Net Regression represent the strength and direction of the relationship between each independent variable and the dependent variable. However, due to the combined penalty terms, the interpretation of coefficients may be more complex.\n",
        "\n",
        "---\n",
        "\n",
        "Q6. **Handling Missing Values in Elastic Net Regression:**\n",
        "   - Missing values in the dataset can be handled by imputation techniques such as mean imputation, median imputation, or using more sophisticated methods like K-nearest neighbors (KNN) imputation or iterative imputation. Once missing values are imputed, Elastic Net Regression can be applied as usual.\n",
        "\n",
        "---\n",
        "\n",
        "Q7. **Using Elastic Net Regression for Feature Selection:**\n",
        "   - Elastic Net Regression inherently performs feature selection by driving some coefficients to zero due to the L1 penalty. By tuning the regularization parameters appropriately, one can control the degree of sparsity in the model and select the most relevant features.\n",
        "\n",
        "---\n",
        "\n",
        "Q8. **Pickling and Unpickling a Trained Elastic Net Regression Model in Python:**\n",
        "   - In Python, you can use the `pickle` module to serialize (pickle) and deserialize (unpickle) a trained Elastic Net Regression model. Here's a basic example:"
      ],
      "metadata": {
        "id": "PB92IYi64d-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import pickle\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "with open('elastic_net_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "with open('elastic_net_model.pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "train_score = loaded_model.score(X_train, y_train)\n",
        "test_score = loaded_model.score(X_test, y_test)\n",
        "\n",
        "print(\"Trained Model Score (R-squared) on Training Data:\", train_score)\n",
        "print(\"Trained Model Score (R-squared) on Testing Data:\", test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ddZ1Ksj4o9_",
        "outputId": "8a2882c8-dfdd-4431-9041-30c66db109a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Model Score (R-squared) on Training Data: 0.9970295766620625\n",
            "Trained Model Score (R-squared) on Testing Data: 0.9970546671780763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. **Purpose of Pickling a Model in Machine Learning:**\n",
        "   - Pickling a model in machine learning allows you to save the trained model to disk in a serialized format. This enables you to reuse the model later without having to retrain it, which can be especially useful for deployment in production environments or sharing with others.\n",
        "   ---"
      ],
      "metadata": {
        "id": "kSheJtUZ4pdB"
      }
    }
  ]
}