{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. **Purpose of Grid Search CV in Machine Learning and How it Works:**\n",
        "   - Grid Search CV (Cross-Validation) is used to tune hyperparameters of a machine learning model by exhaustively searching through a specified grid of hyperparameter values and selecting the combination that yields the best performance.\n",
        "   - It works by performing cross-validation on each combination of hyperparameters and selecting the combination with the highest cross-validated performance score.\n",
        "\n",
        "---\n",
        "\n",
        "Q2. **Difference between Grid Search CV and Randomized Search CV:**\n",
        "   - Grid Search CV exhaustively searches through a specified grid of hyperparameter values, testing all possible combinations, while Randomized Search CV randomly selects a subset of hyperparameter combinations for evaluation.\n",
        "   - Grid Search CV is suitable for a smaller search space, while Randomized Search CV is more efficient for larger search spaces.\n",
        "   - Grid Search CV is more computationally expensive but guarantees finding the optimal solution if it exists, while Randomized Search CV provides a more efficient search but may miss the optimal solution.\n",
        "\n",
        "---\n",
        "\n",
        "Q3. **Data Leakage and Why it's a Problem in Machine Learning:**\n",
        "   - Data leakage refers to the unintentional leakage of information from the training data into the model, leading to inflated performance metrics during training but poor generalization to unseen data.\n",
        "   - Example: Including features in the model that are derived from the target variable or using future information that would not be available at the time of prediction.\n",
        "\n",
        "---\n",
        "\n",
        "Q4. **Preventing Data Leakage in Machine Learning Models:**\n",
        "   - Split the dataset into separate training and testing sets before any preprocessing steps to ensure that information from the testing set does not leak into the training process.\n",
        "   - Avoid using features that would not be available at the time of prediction or derive features based on the target variable only from the training data.\n",
        "\n",
        "---\n",
        "\n",
        "Q5. **Confusion Matrix and its Interpretation:**\n",
        "   - A confusion matrix is a table that visualizes the performance of a classification model by comparing predicted classes against true classes.\n",
        "   - It provides information about the number of true positives, true negatives, false positives, and false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "Q6. **Difference between Precision and Recall:**\n",
        "   - Precision measures the proportion of true positive predictions among all positive predictions made by the model.\n",
        "   - Recall measures the proportion of true positive predictions among all actual positive instances in the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "Q7. **Interpreting a Confusion Matrix to Determine Model Errors:**\n",
        "   - High false positives indicate that the model incorrectly predicts positive instances as negative.\n",
        "   - High false negatives indicate that the model incorrectly predicts negative instances as positive.\n",
        "\n",
        "---\n",
        "\n",
        "Q8. **Common Metrics Derived from a Confusion Matrix:**\n",
        "   - Accuracy, Precision, Recall, F1-score, Specificity, Sensitivity, False Positive Rate, and True Negative Rate.\n",
        "\n",
        "---\n",
        "\n",
        "Q9. **Relationship between Model Accuracy and Confusion Matrix:**\n",
        "   - Accuracy is calculated as the ratio of correctly classified instances (true positives and true negatives) to the total number of instances. It is directly related to the values in the confusion matrix.\n",
        "\n",
        "---\n",
        "\n",
        "Q10. **Using a Confusion Matrix to Identify Biases or Limitations in a Model:**\n",
        "   - Examining the distribution of errors in the confusion matrix can help identify biases or limitations in the model. For example, disproportionate false positives or false negatives may indicate bias towards one class or a problem with the model's generalization ability.\n",
        "   \n",
        "   ---"
      ],
      "metadata": {
        "id": "GAlIIQDq6TB1"
      }
    }
  ]
}