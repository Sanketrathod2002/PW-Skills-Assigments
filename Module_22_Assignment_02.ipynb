{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1: **Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?**\n",
        "\n",
        "- **Overfitting:** Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data instead of the underlying pattern. Consequences include poor generalization to new, unseen data, and high accuracy on training data but low accuracy on test data. Overfitting can be mitigated by techniques such as cross-validation, regularization, and using simpler models.\n",
        "\n",
        "- **Underfitting:** Underfitting occurs when a model is too simple to capture the underlying structure of the data. Consequences include poor performance on both training and test data. Underfitting can be mitigated by using more complex models, increasing the model's capacity, or adding more features to the data.\n",
        "\n",
        "---\n",
        "\n",
        "Q2: **How can we reduce overfitting? Explain in brief.**\n",
        "- Overfitting can be reduced by:\n",
        "  - Using simpler models\n",
        "  - Regularization techniques such as L1 or L2 regularization\n",
        "  - Cross-validation to tune hyperparameters\n",
        "  - Adding more training data\n",
        "  - Feature selection or dimensionality reduction\n",
        "  - Early stopping during training\n",
        "\n",
        "---\n",
        "\n",
        "Q3: **Explain underfitting. List scenarios where underfitting can occur in ML.**\n",
        "- Underfitting occurs when a model is too simple to capture the underlying structure of the data. Scenarios where underfitting can occur include:\n",
        "  - Using a linear model for highly nonlinear data\n",
        "  - Using a low-capacity model for complex data\n",
        "  - Insufficient training data\n",
        "  - Poor feature selection\n",
        "\n",
        "---\n",
        "\n",
        "Q4: **Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?**\n",
        "- The bias-variance tradeoff is the balance between bias and variance in a machine learning model. Bias measures how much the predicted values differ from the true values on average, while variance measures how much the predictions for a given point vary across different training sets. High bias models tend to underfit, while high variance models tend to overfit. The goal is to find the right balance between bias and variance to achieve optimal model performance.\n",
        "\n",
        "---\n",
        "\n",
        "Q5: **Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?**\n",
        "- Common methods for detecting overfitting and underfitting include:\n",
        "  - Visual inspection of learning curves\n",
        "  - Cross-validation\n",
        "  - Model evaluation on a separate test set\n",
        "  - Analysis of bias and variance\n",
        "  - Regularization techniques\n",
        "  - Comparison of training and validation/test performance\n",
        "\n",
        "---\n",
        "\n",
        "Q6: **Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?**\n",
        "- Bias measures how much the predicted values differ from the true values on average, while variance measures how much the predictions for a given point vary across different training sets. High bias models tend to underfit, while high variance models tend to overfit. An example of a high bias model is a linear regression model applied to highly nonlinear data. An example of a high variance model is a complex neural network trained on a small dataset.\n",
        "\n",
        "---\n",
        "\n",
        "Q7: **What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.**\n",
        "- Regularization is a technique used to prevent overfitting by adding a penalty term to the model's loss function. Common regularization techniques include:\n",
        "  - L1 regularization (Lasso): Adds the absolute value of the coefficients to the loss function.\n",
        "  - L2 regularization (Ridge): Adds the squared magnitude of the coefficients to the loss function.\n",
        "  - Dropout: Randomly drops some neurons during training to prevent co-adaptation.\n",
        "  - Early stopping: Stops training when the validation loss starts increasing.\n",
        "  - Data augmentation: Increases the size of the training dataset by applying transformations to the existing data.\n",
        "\n",
        "  ---"
      ],
      "metadata": {
        "id": "FcnN1wtzxYhw"
      }
    }
  ]
}